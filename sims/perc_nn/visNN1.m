function [Y,Xf,Af] = visNN1(X,~,~)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Auto-generated by MATLAB, 30-Jun-2020 21:02:47.
%
% [Y] = myNeuralNetworkFunction(X,~,~) takes these arguments:
%
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = Qx2 matrix, input #1 at timestep ts.
%
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = Qx1 matrix, output #1 at timestep ts.
%
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [-30;-10];
x1_step1.gain = [0.0666666666666667;0.2];
x1_step1.ymin = -1;

% Layer 1
b1 = [17.559913657878752247;13.534421439856943792;-10.455859402867158536;0.24235538700133790746;-1.8863100461125865692;0.012502226912500602821;-0.36328772510852619382;-0.99858149006811680604;0.095166494738478796256;-1.5488002903682940303];
IW1_1 = [-13.599313249229929568 -2.8766553052276355729;-7.1052549450692419342 -5.3320910354667745423;11.39257802398959285 0.2557924900304849869;-1.1436711285586931286 0.90291486949780197513;2.0150626399570272795 -0.62565998494749275327;-1.7398077204954951469 0.74138845903239591895;0.99048390082473924956 -1.0486566236146850351;-0.3249791973027610914 3.5607993095205832113;-1.4531906220428476573 0.80031393490405344782;0.7098398088702438935 -0.40922603241926752693];

% Layer 2
b2 = -2.9673935350275844058;
LW2_1 = [-18.316913006851116563 18.435922386800328354 0.20633028480787235504 -13.931724702054403053 1.1754042583104886699 -3.7225597383953923369 -6.1412293966993143357 0.045178961279830405495 10.74771883033774067 -3.9430134683803039763];

% Output 1
y1_step1.ymin = -1;
y1_step1.gain = 0.00200629435397838;
y1_step1.xoffset = 1.22464679914735e-14;

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX
    X = {X};
end

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
    Q = size(X{1},1); % samples/series
else
    Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS
    
    % Input 1
    X{1,ts} = X{1,ts}';
    Xp1 = mapminmax_apply(X{1,ts},x1_step1);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = repmat(b2,1,Q) + LW2_1*a1;
    
    % Output 1
    Y{1,ts} = mapminmax_reverse(a2,y1_step1);
    Y{1,ts} = Y{1,ts}';
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX
    Y = cell2mat(Y);
end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
y = bsxfun(@minus,x,settings.xoffset);
y = bsxfun(@times,y,settings.gain);
y = bsxfun(@plus,y,settings.ymin);
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
a = 2 ./ (1 + exp(-2*n)) - 1;
end

% Map Minimum and Maximum Output Reverse-Processing Function
function x = mapminmax_reverse(y,settings)
x = bsxfun(@minus,y,settings.ymin);
x = bsxfun(@rdivide,x,settings.gain);
x = bsxfun(@plus,x,settings.xoffset);
end
